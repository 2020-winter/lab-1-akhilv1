{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name(s)\n",
    "**PUT YOUR FULL NAME(S) HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions:** Pair programming assignment. Submit only a single notebook, but make sure to include your first and last names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Classifier\n",
    "\n",
    "## Preface\n",
    "(Courtesy of Dr. Alex Dekhtyar)\n",
    "\n",
    "The core objective of Knowledge Discovery in Data/Data Mining/Machine Learning methods is to provide efficient algorithms for gaining insight from data. CSC 466 primarily studies the methods and the algorithms that enable\n",
    "such insight, and that specifically take this insight above and beyond traditional statistical analysis of data (more\n",
    "about this — later in the course).\n",
    "However, the true power of KDD/DM/ML methods that we will study in this course is witnessed only when\n",
    "these methods are applied to actually gain insight from the data. As such, in this course, the deliverables for your\n",
    "laboratory assignments will be partitioned into two categories:\n",
    "\n",
    "1. KDD Method implementation. In most labs you will be asked to implement from scratch one or more\n",
    "KDD method for producing a special type of insight from data. This part of the labs is similar to your other\n",
    "CS coursework - you will submit your code, and, sometimes, your tests and/or output.\n",
    "\n",
    "2. Insight, a.k.a., data analysis. For each lab assignment we will provide one or more datasets for your\n",
    "perusal, and will ask you to perform the analysis of these datasets using the methods you implemented. The\n",
    "results of this analysis, i.e., the insight, are as important for successful completion of your assignments, as\n",
    "your implementations. Most of the time, you will be asked to submit a lab report detailing your analysis,\n",
    "and containing the answers to the questions you are asked to study.\n",
    "The insight portion of your deliverables is something that you may be seeing for the first time in your CS\n",
    "coursework. It is not an afterthought in your lab assignments. Your grade will, in no small part, depend on\n",
    "the results of your analysis, and the writing quality on your report. This lab assignment, and further assignments\n",
    "will include detailed insturctions on how to prepare reports, and we will discuss report writing several times as\n",
    "the course progresses.\n",
    "\n",
    "## Lab Assignment\n",
    "\n",
    "This is a pair programming assignment. I strongly\n",
    "discourage individual work for this (and other team/pair programming) lab(s), even if you think you can do it\n",
    "all by yourself. Also, this is a pair programming assignment, not a ”work in teams of two” assignment. Pair\n",
    "programming requires joint work on all aspects of the project without delegating portions of the work to individual\n",
    "1\n",
    "team members. For this lab, I want all your work — discussion, software development, analysis of the results,\n",
    "report writing — to be products of joint work.\n",
    "Students enrolled in the class can pair with other students enrolled in the class. Students on the waitlist can\n",
    "pair with other students on the waitlists. In the cases of ”odd person out” situations, a team of three people can\n",
    "be formed, but that team must (a) ask and answer one additional question, and (b) work as a pair would, without\n",
    "delegation of any work off-line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab, we are going to first implement a empirical naive bayesian classifier, then implement a feature importance measure and apply it to a dataset, and finally, we will examine the affect of modifying the priors.\n",
    "\n",
    "For developing this lab, we can use the Titanic Kaggle dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "titanic_df = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/dlsun/data-science-book/master/data/titanic.csv\"\n",
    ")\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only need a few columns, and I will also perform some preprocessing for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['pclass','survived','sex','age']\n",
    "titanic_df = titanic_df.loc[:,features]\n",
    "display(titanic_df)\n",
    "titanic_df.loc[:,'pclass']=titanic_df['pclass'].fillna(titanic_df['pclass'].mode()).astype(int)\n",
    "titanic_df.loc[:,'age']=titanic_df['age'].fillna(titanic_df['age'].median())\n",
    "titanic_df.loc[:,'age']=(titanic_df['age']/10).astype(str).str[0].astype(int)*10\n",
    "titanic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 0\n",
    "In your own words, describe the preprocessing steps I took above.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "Fill in the following function to determine the prior probability of the classes. The result must be in the form of a Python dictionary such as ``priors = {0: 0.4, 1: 0.6}``.\n",
    "<pre>\n",
    "def compute_priors(y):\n",
    "  ???\n",
    "  return priors\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR SOLUTION HERE\n",
    "# CODE FOR TESTING\n",
    "compute_priors(titanic_df['survived'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "The next function to implement is the specific class conditional probability:\n",
    "<pre>\n",
    "def specific_class_conditional(y,yv,x,xv):\n",
    "  ???\n",
    "  return prob\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR SOLUTION HERE\n",
    "specific_class_conditional(titanic_df['survived'],0,titanic_df['sex'],'female')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "Now construct a dictionary based data structure that stores all possible class conditional probabilities (e.g., loop through all possible combinations of values). The keys in your dictionary should be of the form \"pclass=1|survived=0\".\n",
    "\n",
    "<pre>\n",
    "# X is a dataframe that does not contain the class column y.\n",
    "def class_conditional(X,y):\n",
    "  ???\n",
    "  return probs\n",
    "  \n",
    "def prior(y):\n",
    "  ???\n",
    "  return probs\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR SOLUTION HERE\n",
    "display(class_conditional(titanic_df.drop(\"survived\",axis=1),titanic_df[\"survived\"]))\n",
    "display(class_conditional(titanic_df.drop(\"survived\",axis=1),titanic_df[\"survived\"],yname=\"survived\"))\n",
    "\n",
    "display(prior(titanic_df[\"survived\"],yname=\"survived\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "Now you are ready to calculate the posterior probabilities for a given sample. Write and test the following function that returns a dictionary where the keys are of the form \"pclass=1,sex=male,age=60|survived=0\". Make sure you return 0 if the specific combination of values does not exist.\n",
    "<pre>\n",
    "def posteriors(probs,priors,x):\n",
    "    return probs\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR SOLUTION HERE\n",
    "probs = class_conditional(titanic_df.drop(\"survived\",axis=1),titanic_df[\"survived\"],yname=\"survived\")\n",
    "priors = prior(titanic_df[\"survived\"],yname=\"survived\")\n",
    "posteriors(probs,priors,titanic_df.drop(\"survived\",axis=1).loc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5\n",
    "All this is great, but how would you evaluate how we are doing? Let's write a function call train_test_split that splits our dataframe into approximately training and testing dataset. Make sure it does this randomly.\n",
    "<pre>\n",
    "def train_test_split(X,y,test_frac=0.5):\n",
    "   return Xtrain,ytrain,Xtest,ytest\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR SOLUTION HERE\n",
    "Xtrain,ytrain,Xtest,ytest=train_test_split(titanic_df.drop(\"survived\",axis=1),titanic_df[\"survived\"])\n",
    "Xtrain,ytrain,Xtest,ytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6\n",
    "For this exercise, find the conditional probabilities and the priors using a training dataset of size 70% and then using these probabilities find the accuracy if they are used to predict the test dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR SOLUTION HERE\n",
    "Xtrain,ytrain,Xtest,ytest=train_test_split(titanic_df.drop(\"survived\",axis=1),titanic_df[\"survived\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 7\n",
    "For this exercise, you must improve/extend your methods above as necessary to compute the accuracy of predicting the activity from the dataset we've generated in class. Once we have filled out this dataset, I will provide a csv file as well as any preprocessing similar to the Titanic. You may have to modify your functions above to work with both datasets or you may not (depending of course on how you wrote them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR SOLUTION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercises 8\n",
    "For this exercise, I would like you to implement the feature importance algorithm describe in [https://christophm.github.io/interpretable-ml-book/feature-importance.html](https://christophm.github.io/interpretable-ml-book/feature-importance.html). After you implement this, what is the most important feature for our in-class activity prediction dataset? Does this feature make sense to you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR SOLUTION HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md",
   "text_representation": {
    "extension": ".md",
    "format_name": "markdown",
    "format_version": "1.1",
    "jupytext_version": "1.2.4"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
